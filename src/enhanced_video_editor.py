from typing import List
from pathlib import Path
import random
import datetime
from moviepy import (
    ImageSequenceClip,
    VideoFileClip,
    CompositeVideoClip,
    AudioFileClip,
    concatenate_audioclips,
    concatenate_videoclips,
    TextClip,
    ColorClip,
)
from moviepy.video.fx.Loop import Loop
from moviepy.video.fx.FadeIn import FadeIn
from .puzzle import Puzzle
from .enhanced_reaction_selector import EnhancedReactionSelector, ReactionTiming


class VideoTemplate:
    """Video generation templates for different styles."""

    @staticmethod
    def get_difficulty_color(rating: int) -> str:
        """Get color based on puzzle difficulty."""
        if rating < 1200:
            return "green"
        elif rating < 1600:
            return "yellow"
        elif rating < 2000:
            return "orange"
        else:
            return "red"

    @staticmethod
    def get_difficulty_text(rating: int) -> str:
        """Get difficulty text based on rating."""
        if rating < 1200:
            return "BEGINNER"
        elif rating < 1600:
            return "INTERMEDIATE"
        elif rating < 2000:
            return "ADVANCED"
        else:
            return "MASTER"

    @staticmethod
    def create_engagement_hook(puzzle: Puzzle, duration: float = 2.0) -> TextClip:
        """Create engaging opening text."""
        hooks = [
            f"Can you solve this {VideoTemplate.get_difficulty_text(puzzle.rating)} puzzle?",
            f"Only {random.randint(5, 25)}% find the solution!",
            f"Rate {puzzle.rating} chess puzzle - Can you see it?",
            "Find the winning move!" if "mate" in puzzle.themes.lower() else "What's the best move?",
        ]

        hook_text = random.choice(hooks)

        return (
            TextClip(
                "Arial-Bold",
                text=hook_text,
                font_size=48,
                color="white",
                stroke_color="black",
                stroke_width=2,
            )
            .with_duration(duration)
            .with_position(("center", 100))
        )


class EnhancedVideoEditor:
    """Advanced video editor with multi-reaction system and visual enhancements."""

    def __init__(self, gif_dir: Path, audio_dir: Path):
        self.selector = EnhancedReactionSelector(gif_dir, audio_dir)
        self.gif_dir = gif_dir
        self.audio_dir = audio_dir

    def create_multi_reaction_video(self, puzzle: Puzzle, png_files: List[str], output_path: Path, target_width: int = 1080, target_height: int = 1920, template_style: str = "engaging") -> None:
        """Create video with per-move reactions and visual enhancements."""

        move_clips = []
        audio_segments = []
        total_duration = 0

        # Simplified approach without text overlays for testing

        # Process each move with individual reactions
        for move_index, png_file in enumerate(png_files):
            gif_file, audio_file, timing = self.selector.select_reaction_by_context(puzzle, move_index)

            # Create enhanced move clip
            move_clip = self._create_enhanced_move_clip(png_file, gif_file, puzzle, move_index, timing, target_width, target_height)
            move_clips.append(move_clip)

            # Create enhanced audio with crossfading
            audio_clip = self._create_enhanced_audio_segment(audio_file, timing, len(audio_segments) > 0)
            audio_segments.append(audio_clip)
            total_duration += timing.duration

        # Simplified - no celebration overlay for testing

        # Combine all clips
        final_video = concatenate_videoclips(move_clips)
        final_audio = concatenate_audioclips(audio_segments)

        # Skip final audio normalization for testing
        final_video_with_audio = final_video.with_audio(final_audio)

        # Write final video
        final_video_with_audio.write_videofile(str(output_path), codec="libx264", audio_codec="aac", logger=None, preset="medium", bitrate="8000k")

        # Cleanup
        for clip in move_clips + audio_segments + [final_video, final_audio, final_video_with_audio]:
            if hasattr(clip, "close"):
                clip.close()

    def _create_enhanced_move_clip(self, png_file: str, gif_file: Path, puzzle: Puzzle, move_index: int, timing: ReactionTiming, target_width: int, target_height: int) -> CompositeVideoClip:
        """Create enhanced move clip with visual improvements."""

        # Create base chess board clip
        board_clip = ImageSequenceClip([png_file], durations=[timing.duration])

        # Create gradient background
        gradient_bg = self._create_gradient_background(target_width, target_height, timing.duration, puzzle.rating)

        # Load and process GIF
        gif_clip = VideoFileClip(str(gif_file))

        # Resize board to fit in upper portion
        board_height = int(target_height * 0.6)
        board_resized = board_clip.resized(height=board_height)
        _, board_h = board_resized.size

        # Calculate GIF area
        gif_area_height = target_height - board_h - 100  # Leave space for text
        gif_resized = gif_clip.resized(height=min(gif_area_height, target_width))

        # Loop GIF for clip duration
        gif_looped = Loop(duration=timing.duration).apply(gif_resized)

        # Add fade effects based on energy level
        if timing.energy_level == "high":
            gif_looped = FadeIn(0.2).apply(gif_looped)

        # Position elements
        board_positioned = board_resized.with_position(("center", 50))
        gif_positioned = gif_looped.with_position(("center", board_h + 75))

        # Simplified composition without text overlays
        composite = CompositeVideoClip([gradient_bg, board_positioned, gif_positioned], size=(target_width, target_height))

        return composite

    def _create_gradient_background(self, width: int, height: int, duration: float, rating: int) -> ColorClip:
        """Create animated gradient background based on puzzle difficulty."""
        color = VideoTemplate.get_difficulty_color(rating)

        color_map = {"green": (20, 60, 20), "yellow": (60, 60, 20), "orange": (80, 40, 20), "red": (80, 20, 20)}

        bg_color = color_map.get(color, (30, 30, 30))
        return ColorClip(size=(width, height), color=bg_color).with_duration(duration)

    def _create_move_indicator(self, puzzle: Puzzle, move_index: int, duration: float) -> TextClip:
        """Create move indicator text."""
        if move_index == 0:
            text = "Find the best move!"
        elif move_index == len(puzzle.moves) - 1:
            text = "Solution!"
        else:
            text = f"Move {move_index + 1}"

        return (
            TextClip(
                "Arial-Bold",
                text=text,
                font_size=36,
                color="white",
                stroke_color="black",
                stroke_width=1,
            )
            .with_duration(duration)
            .with_position(("center", "bottom"))
            .with_margin(bottom=20)
        )

    def _create_difficulty_badge(self, puzzle: Puzzle, duration: float) -> TextClip:
        """Create difficulty rating badge."""
        difficulty_text = f"{VideoTemplate.get_difficulty_text(puzzle.rating)} â€¢ {puzzle.rating}"
        color = VideoTemplate.get_difficulty_color(puzzle.rating)

        text_color_map = {"green": "lightgreen", "yellow": "gold", "orange": "orange", "red": "salmon"}

        return (
            TextClip(
                "Arial-Bold",
                text=difficulty_text,
                font_size=24,
                color=text_color_map.get(color, "white"),
                stroke_color="black",
                stroke_width=1,
            )
            .with_duration(duration)
            .with_position((20, 20))
        )

    def _create_celebration_overlay(self, puzzle: Puzzle, width: int, height: int) -> CompositeVideoClip:
        """Create celebration overlay for puzzle completion."""
        bg = ColorClip(size=(width, height), color=(0, 50, 0)).with_duration(2.0)

        celebration_texts = ["Puzzle Solved! ðŸŽ‰", "Well Done! â­", "Excellent! ðŸ‘", "Master Move! ðŸ†"]

        text = random.choice(celebration_texts)
        text_clip = (
            TextClip(
                "Arial-Bold",
                text=text,
                font_size=56,
                color="gold",
                stroke_color="darkgreen",
                stroke_width=3,
            )
            .with_duration(2.0)
            .with_position("center")
        )

        # Add themes if available
        if puzzle.themes:
            themes_text = f"Theme: {puzzle.themes.replace(' ', ', ').title()}"
            themes_clip = (
                TextClip(
                    "Arial",
                    text=themes_text,
                    font_size=32,
                    color="lightgreen",
                )
                .with_duration(2.0)
                .with_position(("center", height - 150))
            )

            return CompositeVideoClip([bg, text_clip, themes_clip])

        return CompositeVideoClip([bg, text_clip])

    def _create_enhanced_audio_segment(self, audio_file: Path, timing: ReactionTiming, has_previous: bool) -> AudioFileClip:
        """Create enhanced audio with crossfading and normalization."""
        audio_clip = AudioFileClip(str(audio_file))

        # Trim or loop to match timing
        if audio_clip.duration > timing.duration:
            audio_clip = audio_clip.subclipped(0, timing.duration)
        elif audio_clip.duration < timing.duration:
            loops_needed = int(timing.duration / audio_clip.duration) + 1
            audio_clips = [audio_clip] * loops_needed
            audio_clip = concatenate_audioclips(audio_clips).subclipped(0, timing.duration)

        # Simplified audio processing - skip normalization for now

        return audio_clip


def create_base_video(png_files: List[str], output_path: Path, fps: int) -> VideoFileClip:
    """Legacy function for backward compatibility."""
    clip = ImageSequenceClip(png_files, fps=fps)
    clip.write_videofile(str(output_path), codec="libx264", logger=None)
    result = VideoFileClip(str(output_path))
    clip.close()
    return result


def generate_timestamped_path(base_dir: Path, prefix: str, suffix: str) -> Path:
    """Generate timestamped file path."""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    return base_dir / f"{prefix}_{timestamp}{suffix}"
